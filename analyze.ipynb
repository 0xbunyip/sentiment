{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_of_gameplay</th>\n",
       "      <th>content_review</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>funny_vote</th>\n",
       "      <th>number_comment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>484.4</td>\n",
       "      <td>Such a great game.... but it will suck you in ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>724.0</td>\n",
       "      <td>Silver=Global                                 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1315.4</td>\n",
       "      <td>The game of a generation. Travel the globe and...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>64.6</td>\n",
       "      <td>I have been playing Counter-Strike since 1.5 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>630.0</td>\n",
       "      <td>I think this might be the best game ever.CSGO ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hour_of_gameplay                                     content_review  \\\n",
       "ID                                                                         \n",
       "730             484.4  Such a great game.... but it will suck you in ...   \n",
       "730             724.0  Silver=Global                                 ...   \n",
       "730            1315.4  The game of a generation. Travel the globe and...   \n",
       "730              64.6  I have been playing Counter-Strike since 1.5 a...   \n",
       "730             630.0  I think this might be the best game ever.CSGO ...   \n",
       "\n",
       "     helpful_vote  total_vote  funny_vote  number_comment  polarity  \n",
       "ID                                                                   \n",
       "730             2           2           1               1         1  \n",
       "730             1           2           0               1         0  \n",
       "730             4           4           0               5         1  \n",
       "730             1           1           0               0         0  \n",
       "730             2           2           0               0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_csv('../data/clean/train_reviews.csv')\n",
    "val_df = pd.DataFrame.from_csv('../data/clean/val_reviews.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13834 entries, 730 to 440\n",
      "Data columns (total 7 columns):\n",
      "hour_of_gameplay    13834 non-null float64\n",
      "content_review      13834 non-null object\n",
      "helpful_vote        13834 non-null int64\n",
      "total_vote          13834 non-null int64\n",
      "funny_vote          13834 non-null int64\n",
      "number_comment      13834 non-null int64\n",
      "polarity            13834 non-null int64\n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 864.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df[train_df.content_review.isnull()]\n",
    "train_df.dropna(inplace = True)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(reviews_df, vectorizer = None):\n",
    "    reviews = reviews_df.content_review.values\n",
    "    \n",
    "    if vectorizer is None:\n",
    "        vectorizer =  CountVectorizer(stop_words = 'english', min_df = 0.001, max_df = 0.8, max_features = 10000)\n",
    "        vectorizer.fit(reviews)\n",
    "        \n",
    "    X_content_review = vectorizer.transform(reviews).toarray()\n",
    "    X = np.hstack((np.ones((len(X_content_review), 1)), X_content_review\n",
    "                   , reviews_df.helpful_vote.values.reshape(-1, 1), reviews_df.total_vote.values.reshape(-1, 1)\n",
    "                   , reviews_df.funny_vote.values.reshape(-1, 1), reviews_df.number_comment.values.reshape(-1, 1)))\n",
    "    Y = reviews_df.polarity.values.reshape(-1, 1)\n",
    "    return vectorizer, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13834, 7266) (13834, 1)\n",
      "(2769, 7266) (2769, 1)\n"
     ]
    }
   ],
   "source": [
    "vectorizer, X_train, Y_train = vectorize_data(train_df)\n",
    "_, X_val, Y_val = vectorize_data(val_df, vectorizer)\n",
    "print X_train.shape, Y_train.shape\n",
    "print X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, X_mean = None, X_std = None):\n",
    "    if X_mean is None:\n",
    "        X_mean = X[:, 1 :].mean(axis = 0)\n",
    "    if X_std is None:\n",
    "        X_std = X[:, 1 :].std(axis = 0)\n",
    "        \n",
    "    X[:, 1 :] = (X[:, 1 :] - X_mean) / X_std\n",
    "    return X_mean, X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.88794894e-15  -4.63821871e-15 ...,  -4.35749295e-15\n",
      "   3.55689086e-15  -2.07090120e-15] [ 0.  1.  1. ...,  1.  1.  1.]\n",
      "[ 1.          0.01587495 -0.00708178 ..., -0.00375977  0.00669722\n",
      " -0.00899576] [ 0.          1.19452817  0.79919985 ...,  0.90281573  0.98006287\n",
      "  0.91318821]\n"
     ]
    }
   ],
   "source": [
    "X_mean, X_std = preprocess_data(X_train)\n",
    "_ = preprocess_data(X_val, X_mean, X_std)\n",
    "print X_train.mean(axis = 0), X_train.std(axis = 0)\n",
    "print X_val.mean(axis = 0), X_val.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(S):\n",
    "    '''\n",
    "    Computes sigmoid function for each element of array S.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-S))\n",
    "def softmax(S):\n",
    "    '''\n",
    "    Computes softmax function for each row of array S.\n",
    "    '''\n",
    "    A = np.exp(S)\n",
    "    A /= A.sum(axis=1, keepdims=True)\n",
    "    return A\n",
    "def compute_nnet_outputs(Ws, X, need_all_layer_outputs):\n",
    "    '''\n",
    "    Computes the outputs of Neural Net by forward propagating X through the net.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Ws : list of numpy arrays\n",
    "        Ws[l-1] is W of layer l with l >= 1 (layer 0 is input layer; it doesn't have W);\n",
    "        W of layer l will have the shape of (d^(l-1)+1, d^(l)), where \n",
    "        d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1 and \n",
    "        d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "    X : numpy array, shape (N, d+1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    need_all_layer_outputs : bool\n",
    "        If this var is true, we'll return a list of layer's-outputs; \n",
    "        otherwise, we'll return the final layer's output.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If `need_all_layer_outputs` is false, return\n",
    "        A : numpy array, shape (N, K=10)\n",
    "            The maxtrix of output vectors of final layer; each row is an output vector (containing \n",
    "            each class's probability given the corresponding input vector).\n",
    "    Else, return\n",
    "        As : list of numpy arrays\n",
    "            As[l] is the matrix of output vectors of layer l; each row is an output vector (corresponding \n",
    "            to an input vector).\n",
    "    '''    \n",
    "    A = X\n",
    "    As = [X]\n",
    "    for i in xrange(len(Ws)):\n",
    "        A = A.dot(Ws[i])\n",
    "        if i + 1 < len(Ws):\n",
    "            A = np.hstack((np.ones((A.shape[0], 1)), sigmoid(A)))\n",
    "        else:\n",
    "            A = softmax(A)\n",
    "        if need_all_layer_outputs:\n",
    "            As.append(A)\n",
    "    \n",
    "    if need_all_layer_outputs:\n",
    "        return As\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes, wd_level,\n",
    "               mb_size, learning_rate, max_patience, max_epoch=1000000, momentum_param=0.):\n",
    "    '''\n",
    "    Trains Neural Net on the dataset (X, Y).\n",
    "    Cost function: mean negative log likelihood + weight decay.\n",
    "    Optimization algorithm: SGD; stopping criteria: early stopping and/or max epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    hid_layer_sizes : list\n",
    "        The list of hidden layer sizes; e.g., hid_layer_sizes = [20, 10] means: \n",
    "        the Net has 2 hidden layers, the 1st one has 20 neurons, and the 2nd one has \n",
    "        10 neurons (not count the +1 neurons).\n",
    "    wd_level : float\n",
    "        The level (coefficient) of weight decay.\n",
    "    mb_size : int\n",
    "        Minibatch size of SGD.\n",
    "    learning_rate : float\n",
    "        Learning rate of SGD.\n",
    "    max_patience : int (> 0) or None\n",
    "        The parameter of early stopping. We'll have a `patience` variable with initial value equal to\n",
    "        `max_patience`. During the training, we'll keep track of the best MBE (Mean Binary Error) \n",
    "        on the validation set; if the MBE on the validation set at the current epoch < the current \n",
    "        best one, we'll reset `patience` to `max_patience`; otherwise, `patience` -= 1. \n",
    "        When `patience` = 0 or `max_epoch` is reached, we'll terminate SGD.\n",
    "        If `max_patience` is None, we don't use early stopping.\n",
    "    max_epoch : int, default 1000000\n",
    "        We'll terminate SGD after this number of epochs or when `patience` = 0 (if early stopping is used).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Ws : list of numpy arrays\n",
    "        Ws[l-1] is W of layer l with l >= 1 (layer 0 is input layer; it doesn't have W);\n",
    "        W of layer l will have the shape of (d^(l-1)+1, d^(l)), where \n",
    "        d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1 and \n",
    "        d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "        *If `max_patience` is None, Ws are weights after the final epoch (as previous homeworks); \n",
    "        otherwise, Ws are weights corresponding to the best MBE on the validation set.*\n",
    "    train_errs : list, len = num epochs spent on training\n",
    "        The list of MBEs on the training set after each epoch.\n",
    "    val_errs : list, len = num epochs spent on training\n",
    "        The list of MBEs on the validation set after each epoch.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    After each *100-epochs* (in the experiments below, you'll not want to print after each single epoch), \n",
    "    you need to print out: \n",
    "    - The MBE on the training set and validation set (regardless of `max_patience`).\n",
    "    - The value of `patience` (if `max_patience` is not None).\n",
    "    E.g., `Epoch ..., training err ..., val err ..., patience ...` (in this case, `max_patience` is not None).\n",
    "    \n",
    "    After the training, you need to print out the info of returned Ws:\n",
    "    - The corresponding epoch.\n",
    "    - The corresponding MBE on the training set and validation set.\n",
    "    E.g., `Info of returned Ws: epoch ..., train err ..., val err ...`.\n",
    "    '''\n",
    "    # Init Ws\n",
    "    K = len(np.unique(train_Y)) # Num classes\n",
    "    layer_sizes = [train_X.shape[1] - 1] + hid_layer_sizes + [K]\n",
    "    np.random.seed(0) # This will fix the randomization; so, you and me will have the same results\n",
    "    Ws = [np.random.randn(layer_sizes[l]+1, layer_sizes[l+1]) / np.sqrt(layer_sizes[l]+1) \n",
    "          for l in range(len(layer_sizes)-1)]\n",
    "    best_Ws = [np.copy(W) for W in Ws]\n",
    "    \n",
    "    Vs = [np.zeros_like(W) for W in Ws]\n",
    "    train_errs = []\n",
    "    val_errs = []\n",
    "    N = train_X.shape[0]\n",
    "    mbid = np.arange(N)\n",
    "    Y_onehot = np.zeros((N, K))\n",
    "    Y_onehot[np.arange(N).reshape(-1, 1), train_Y] = 1\n",
    "    patience = max_patience\n",
    "    best_val_err = 1000\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in xrange(max_epoch):\n",
    "        np.random.shuffle(mbid)\n",
    "        \n",
    "        for i in xrange(0, N, mb_size):\n",
    "            M = min(N, i + mb_size) - i\n",
    "            As = compute_nnet_outputs(Ws, train_X[mbid[i : i + mb_size], :], True)\n",
    "            \n",
    "            delta = As[-1] - Y_onehot[mbid[i : i + mb_size], :]\n",
    "            Wgrad = As[-2].T.dot(delta) + 2 * M * wd_level * Ws[-1]\n",
    "            \n",
    "            for l in xrange(1, len(layer_sizes)):\n",
    "                if l + 1 < len(layer_sizes):\n",
    "                    delta = (delta.dot(Ws[-l].T) * As[-l - 1] * (1. - As[-l - 1]))[:, 1:]\n",
    "                Vs[-l] = momentum_param * Vs[-l] - learning_rate * Wgrad / M\n",
    "                Ws[-l] += Vs[-l]\n",
    "                if l + 1 < len(layer_sizes):\n",
    "                    Wgrad = As[-l - 2].T.dot(delta) + 2 * M * wd_level * Ws[-l - 1]\n",
    "            \n",
    "        A = compute_nnet_outputs(Ws, train_X, False)\n",
    "        train_err = np.mean(A.argmax(axis = 1).reshape(-1, 1) != train_Y) * 100\n",
    "        train_errs.append(train_err)\n",
    "        \n",
    "        A = compute_nnet_outputs(Ws, val_X, False)\n",
    "        val_err = np.mean(A.argmax(axis = 1).reshape(-1, 1) != val_Y) * 100\n",
    "        val_errs.append(val_err)\n",
    "        \n",
    "        if max_patience is not None:\n",
    "            patience -= 1\n",
    "            if val_err < best_val_err:\n",
    "                best_val_err = val_err\n",
    "                best_epoch = epoch\n",
    "                patience = max_patience\n",
    "                best_Ws = [np.copy(W) for W in Ws]\n",
    "        else:\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            if max_patience is not None:\n",
    "                print \"Epoch %d, training err %.3f, val err %.3f, patience %d\" % (epoch, train_err, val_err, patience)\n",
    "            else:\n",
    "                print \"Epoch %d, training err %.3f, val err %.3f\" % (epoch, train_err, val_err)\n",
    "                \n",
    "        if max_patience is not None and patience <= 0:\n",
    "            break\n",
    "            \n",
    "    print \"Info of returned Ws: epoch %d, train err %.3f, val err %.3f\" % \\\n",
    "                (best_epoch, train_errs[best_epoch], val_errs[best_epoch])\n",
    "        \n",
    "    if max_patience is not None:\n",
    "        return (best_Ws, train_errs, val_errs)\n",
    "    return (Ws, train_errs, val_errs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training err 9.202, val err 10.798, patience 5\n",
      "Epoch 1, training err 6.686, val err 8.162, patience 5\n",
      "Epoch 2, training err 5.667, val err 7.692, patience 5\n",
      "Epoch 3, training err 5.450, val err 7.548, patience 5\n",
      "Epoch 4, training err 4.995, val err 7.476, patience 5\n",
      "Epoch 5, training err 5.226, val err 7.728, patience 4\n",
      "Epoch 6, training err 4.648, val err 7.584, patience 3\n",
      "Epoch 7, training err 5.674, val err 7.801, patience 2\n",
      "Epoch 8, training err 5.176, val err 7.765, patience 1\n",
      "Epoch 9, training err 4.850, val err 7.692, patience 0\n",
      "Info of returned Ws: epoch 4, train err 4.995, val err 7.476\n"
     ]
    }
   ],
   "source": [
    "Ws_0, train_errs_0, val_errs_0 = train_nnet(X_train, Y_train, X_val, Y_val, hid_layer_sizes=[50], \n",
    "                                            wd_level=0.01, mb_size=32, learning_rate=0.03, \n",
    "                                            max_patience=5, max_epoch=50, momentum_param=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
